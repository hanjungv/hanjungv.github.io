---

layout: post
title: "(CS) OS 리뷰"
category: CS

---

# OS 리뷰
## 시작하면서
> 블로그 글 작성이 너무나 오랜만이다. 그동안 블로그 글을 싼 것을 보면서..(쓴 것이라고 표현하기엔 적당하지 않은 것 같다.) 이런 글을 계속해서 올리는게 과연 도움이 될 까 하는 생각이 들었다. 앞으로 조금 태도를 바꿔서 하나하나 신경을 써서 글을 올리되 기존에 썼던 글을 다듬는 시간을 좀 가지려 한다. 우선 이 글은 취준생으로써 학사과정에 배웠던 OS를 리뷰하는 글이다. 시험 준비를 하기 위한 글이니 하나하나 보는 것이 아닌 핵심이라 말씀해주셨던 부분을 중심으로 보려한다.

## (흠?)은 뭐지
* 과연 여기까지 나올까 싶은 것들은 흠? 을 앞에 붙여봤다.. 물론 제 주관이니 아무 의미 없는 것이라고 말할 수 있다. 

## 1장(Introduction)
> 한 학기 개요를 말하는 곳이다.

1. OS가 뭐라고 생각하나?
    * 단순하게 말해서 "컴퓨터 하드웨어와 실행되는 프로그램 모두를 제어하는 프로그램이다."라고 표현하면 적합 할 것 같다.
2. I/O 장치와 CPU가 동시에 일을 할 수 있나?
    * 그렇다. 이유는 "DMA(Direct Memory Access)"때문이다.
3. 그럼 DMA과정을 간략하게 말해보자
    1. CPU에서 각 장치에 있는 컨트롤러에 해당되는 일을 CPU에 올리라 명령한다.
    2. 그리고 CPU의 간섭없이 열심히 job을 메모리에 올린다.
    3. 전부 올리게 되면 `interrupt`를 통해 CPU에 알려주고 일을 마무리 한다.
4. Interrupt라고 했는데 interrupt에 대해 설명해 볼 수 있나?
    * 인터럽트는 장치 내에서 예외상황이 발생하여 처리가 필요할 때 사용하는 것을 말합니다. `interrupt vector`에 그러한 인터럽트 신호가 오게 될 때 처리해야 하는 동작을 가리키는 주소를 적어놔 관리하게 됩니다. 무조건 우선적으로 처리되게 됩니다.
5. 혹시 Trap 과 Interrupt의 차이를 아는가?
    * Trap 은 S/W적으로 발생하는 인터럽트를 가리키는 명칭으로 알고있습니다. 예로 System Call, Segmentation fault 같은게 있습니다.
    * 인터럽트는 컨트롤 씨를 누를때 처럼 H/W에서 발생하는 것을 명칭 하는 것으로 알고 있습니다.

## 2장(System Structure)
> System Call과 구조에 대해 간략히 설명한다.

1. System Call을 설명해 볼 수 있을까?
    * System Call은 Application program에서 OS로 서비스를 요청하고 싶을 때 쓰는 메카니즘이다. 주로 바로 커널 명령어를 호출하지 않고 POSIX같은 라이브러리를 사용한다.
2. 그럼 왜 굳이 라이브러리를 사용할까?
    * 우리는 여러 OS를 사용한다. 이 모든 OS마다 각각 커널 명령어는 다를 것이다. 고로 API라이브러리를 사용 한다면 Portability가 증가할 것이고 프로그래밍은 쉬워질 것이다. System Call도 결국 라이브러리를 호출 할 것이고 `System Call Interface`라는 table구조를 사용하여 일을 진행한다.
3. (흠?) 마이크로 커널이 뭔지 간략하게 설명해 볼 수 있을까?
    * OS중 핵심 기능만 kernel에 두고 나머지는 유저 영역에 두는 오에스 구조입니다.
    * 확장성이 좋고 porting이 쉽습니다. 하지만 유저 영역에서 수행해야 하는 일이 많아져 일이 많다면 오버헤드가 큽니다.

## 3장(Process Concept)
> Process에 대해 소개하고 통신법을 소개한다.

1. Process와 Program의 차이가 뭘까?
    * "실행 되고 있는 프로그램"을 프로세스라고 한다. 실행이 되고 있는 프로그램이기 때문에 Program Code + Heap/Stack 영역+ Data영역 + PCB 등 훨씬 더 많은 것을 가지고 있다.
2. PCB라고 했는데 PCB에 대해 설명해 볼 수 있나?
    * `Process Control Block`의 약어이다. 이름에서 나타나는 것처럼 프로세스의 정보를 모두 담고있는 구조체이다. 현재상태, 다음 수행위치, CPU 레지스터 값(인터럽트 후 바로 실행해야 할 때 저장해 놓은 값들), 스케줄링 정보 등등을 담고 있다.
3. I/O bound Process 와 CPU bound Process를 비교 할 수 있나?
    * I/O bound Process가 CPU bound Process보다 자주, 짧게 일어나게 된다. 주로 스케줄링을 하여 우선적으로 일하는 것은 전자를 선택한다.
4. 그럼 Process 스케줄러에 대해 아는 것을 전부 말해보자
    * Long-term scheduler : 프로그램을 실행한다고 더블클릭을 했다 치면 Long-term 같은 경우에 ready-queue에서 메모리로 어떤 일을 올릴지 고민하게 됩니다. 자주 일어나지 않고 요즘은 사용을 거의 안한다고 할 수 있습니다. 요즘은 그냥 다 올립니다.
    * Short-term scheduler : 다음 task를 어떤것을 선택할 지 CPU에서 자주 일어나는 스케줄러 입니다.
    * mid-term scheduler : 모든 task를 메모리에 올릴 수 없으니 어떤 task를 선택하여 swapping 할 지 정하는 것입니다.
5. Context Switch에 대해 그럼 설명해보자
    * Context Switch는 CPU에서 process를 switch할 때 발생하는 과정을 의미한다. 이때 이전 프로세스의 상태를 저장해서 종료를 해야하고 새로운 프로세스의 상태를 가지고 와서 로드를 해줘야하는데 이 때 상당한 오버헤드가 발생한다.
6. (흠?)`fork`를 통해 프로세스를 만든다 치면 이때 자원을 공유하나?
    * file은 공유하지만 나머지 영역들은 공유를 하지 않는다. 
    * `Call once return twice`라고 하는데 부모 프로세스에서 한번 호출하지만 pid는 각각 2개가 리턴되게 된다. 자식 process의 id는 0이다.
    * 내가 코딩했었던 방식은 주로 부모 프로세스에서 fork를 한 뒤 자식 프로세스에서 코드를 수정한 뒤 exec을 통해 새로운 프로그램을 수행한 후 종료되면 자식 프로세스를 거두게 된다.
    * 만약 `wait` System Call을 통해 자식 프로세스를 거두지 않고 종료하게 된다면 고아프로세스가 된다.
7. 각 프로세스간 통신은 어떻게 하는지 방식에 대해 설명해보자!
    * Message Passing : receive, send System Call을 이용하여 메세지를 전달하게 된다. 직접 전달과 간접 전달 방법을 갖게 된다. OS의 간섭이 지속적으로 필요하게 된다. 시간이 오래걸리게 된다.
    * Shared Memory : 각 프로세스간 공유하는 공간을 만들어 다른 프로세스에서 그곳에 attach 하여 사용하게 된다. 처음 생성과 attach시 System Call을 사용하지만 이후에는 커널 영역에서 작업이 이루어지지 않아 지속적으로 교류가 많을 때 사용하면 유리하다.

## 4장(Multithreaded Programming)
> thread에 대한 간략한 개념이 나오게 된다.

1. Process와 thread를 비교하여 설명할 수 있는가?
    * 먼저 한가지 상황을 가정해보면 한 Server에서 같은 일을 수행하는 프로세스를 매번 fork 해서 만든다고 해보자. 이런 상황이 존재한다면 매번 동일한 코드를 복사하여 일을 수행하는 비효율적인 모습을 상상할 수 있다. fork를 하게 되면 PCB, 주소복사 등등 해줄 일이 많다. 그래서 등장한게 쓰레드인데 한 프로세스 내에서 독립적인 일을 수행해준다.
    * 쓰레드는 레지스터와 스택을 제외하고는 모두 공유하여 사용하게 된다. 이렇게 될 경우 한가지 쓰레드가 I/O를 수행할 때 다른 쓰레드는 다른일을 하는 식으로 일을 좀 더 효율적으로 수행할 수 있게 된다. 그리고 요즘같이 multi-processor 환경을 갖춘 상태에서는 쓰레드로 각 CPU에 일을 할당해서 수행해 줄 수 있게 된다.
2. (흠?) user thread와 kernel thread를 many-to-many 모델로 구성했다면 스케줄링은 어떻게 할까?
    * `LWP(LightWeight Process)`라는 것을 통해 커널의 정보를 유저 쓰레드에 전달하고 라이브러리 단에서 다음 일을 결정하여 일을 정해주게 된다. 이를 `upcall`이라 한다.

## 5장(Process Scheduling)
> 스케줄링 기법에 대해 설명한다.

1. 스케줄러가 결정을 내리는 시점에 있어서 Preemptive 한 것과 Nonpreemptive 한 것의 차이가 뭐냐?
    * Nonpreemptive한 것은 프로세스가 자발적으로 CPU를 포기 할 때까지 기다리는 것이다. Preemptive 같은 경우 당장 그 시점에서 우선순위가 높은 것을 찾게 된다.
2. 그럼 interrupt같은 경우는 어떻게 되는 건가?
    * interrupt로 수행되는 작업은 non-preemptive하게 이뤄져야 한다.
3. 스케줄링 기법을 정하는 기준에 대해 설명해 볼 수 있을까?
    * CPU utilization, Throughput, Turnaround time, Waiting time, Response time등이 기준이 된다. 
    * Turnaround time 같은 경우는 프로세스 끝낸시간 - 시작시간, Wating time는 레디 큐에서 기다리는 시간이다. Response time은 첫번째 응답이 온 시간이다.
4. 그럼 이 기준에 따라서 알고있는 스케줄링 기법들을 설명해봐라
    * FCFS(First Come First Served): 온 순서대로 수행한다. 이렇게 수행할 경우 수행시간이 긴 것이 먼저 올 경우 뒤에 task가 수행을 못하는 `convoy effect`가 발생할 수 있다.
    * SJF(Shortest Job First): burst time이 짧은 것을 우선적으로 수행하게 된다. 이럴 경우 burst time이 긴 일은 계속해서 실행이 안되는 `starvation` 현상이 발생할 수 있다. 물론 지금 수행하는 task가 얼마나 걸릴지 알 수 없다는 문제도 있다.(이런경우 예측을 해서 사용한다.)
    * Priority: 프로세스에 우선순위를 주어 일을 수행하게 된다. 이 경우에도 우선순위가 낮은 일은 계속해서 실행이 안되는 `starvation` 이 발생할수 있다.
    * RR(Round-robin) : CPU time의 단위를 정해 그 time 대로 한번씩 일을 번갈아 가면서 수행한다. 이 경우 Response time이 보장되는 장점이 있지만 time quantum이 짧을 경우 context-switch 에 따른 오버헤드가 커진다.
5. 그럼 Multi-processor 스케줄링에서 영향을 미치는 것에는 어떤게 있냐?
    * `Process affinity`라는 게 영향을 미치게 된다. 이건 이전에 이 프로세스를 이 CPU에서 실행한 적이 있는가를 의미하게 되는데 이 경우 해당 코드의 일부가 캐시에 담겨져 있을 가능성이 높으니 이전에 실행했던 CPU를 선택하게 된다.
    * `Load balancing` CPU마다 utilization을 체크해서 바쁜 쪽의 일을 덜 바쁜 쪽으로 가지고 와 수행하게 된다. 

## 6장(Process synchronization)
> Critical Section에 대한 개념과 Semaphore에 대해 등장하게 된다.

1. Race condition에 대해 설명할 수 있을까?
    * 같은 데이터에 동시 접근이 가능하게 되어 결과값이 특정 순서에 따라 달라질 수 있게 된 환경을 의미합니다.
    * 이렇게 공유 변수 접근에 가능한 영역을 Critical section이라 합니다.
2. 그럼 그런 문제를 어떻게 해결할 수 있을까?
    * 3가지 조건을 만족하면 됩니다.
        * Mutual Exclusion: Critical Section에 어떤 프로세스가 일을 하고 있다면 다른 thread는 block 시킵니다.
        * Progress: CPU가 일을 안하고 있다면 바로 기다리는 일을 진행시켜줍니다.
        * Bounded waiting: 기다리는 일이 진입할 수 있다는 보장이 있어야 합니다.
3. Semaphore란 무엇인지 설명할 수 있을까?
    * 공유 자원 제한 접근을 위해 사용하는 변수입니다. 주로 binary로 사용을 하고 두가지 함수가 있습니다. `signal()`, `wait()` 함수로 변수의 값을 증감 시키고 비교합니다. wait상태에 semaphore 값이 0이거나 0보다 작을 경우 그 자리에서 기다리게 됩니다. 이후 일을 종료하고 나가는 함수가 signal을 하게 되면 세마포어 값이 증가하여 critical section에 진입 할 수 있게 됩니다. 
    * binary Semaphore === mutex

## 7장(Deadlocks)
> Deadlock에 대한 설명과 회피, 탐지, 해결 방법등을 설명한다.

1. Deadlock이 발생할 수 있는 4가지 필요조건에 대해 설명해 봐라
    1. Mutual Exclusion : 자원을 동시에 여러프로세스에서 사용하지 못한다.
    2. Hold & Wait : 하나의 자원을 가지고 다른 자원을 요청하는 상태여야 한다.
    3. Circular wait : 자원을 Hold - Request 하는 관계가 cycle을 이룬다.
    4. No preemption : preemption 하게 일이 진행되면 안된다.
2. 그럼 위의 4가지 조건을 만족하면 무조건 Deadlock이 발생하는가?
    * 그렇지 않다. 위의 4가지 조건을 만족해도 발생할 수도 있고 안할 수도 있다. 그러나 4가지 중 하나라도 조건을 만족하지 않으면 데드락은 없다. 고로 데드락을 발생시키지 않게 예방(prevention)을 하려면 자원을 한번에 여러곳에서 사용할 수 있게 하든지 preemption하게 하든지 위의 4가지 조건을 만족시키지 않으면 된다. 하지만 여기서 부수적으로 문제가 발생할 수도 있으니 여러 이슈를 고려해 봐야한다.
3. 위의 설명을 좀 자세히 할 수 있을까? 어떤 이슈들이 있나
    * Mutual Exclusion 조건을 만족시키지 않게 하기 위해 여러 곳에서 자원을 요청, 사용가능하게 한다면 race condition이 발생할 것입니다.
    * Hold&Wait 라고 한다면 모든 자원이 동시에 사용이 가능할 때 사용을 하는 것이기 때문에 starvation, low CPU utilization 의 문제 또한 있을 것입니다.
    * preemption을 허용한다면 프린터 같이 한번에 no preemption 하게 일어나야 하는 일들에 문제가 생길수도 있습니다. 
4. 데드락을 또 회피(Avoidance)하는 방법이 있을까?
    * 자원의 갯수를 먼저 예측, 파악해 봅니다. 그리고 이 갯수가 프로세스에서 사용할 자원의 갯수보다 작다면 데드락은 절대 발생하지 않습니다. 이런 safe한 상태일 때만 일을 우선적으로 한다면 데드락이 발생하지 않을 것입니다. 이렇게 safe한 상태를 알기 위해 multiple instance에서 `Banker's Algorithm`을 사용합니다. 
5. 데드락이 걸렸을 때 회복하는 방법이 뭐가 있을까?
    * 죽이던지
    * 체크포인트를 잡고 롤백을 하던지

## 8장(Memory management Strategies)
> 3가지 메모리 관리 전략에대해 설명한다.

1. CPU에서 전달한 Virtual Address를 메모리에서 어떻게 찾는지 간략하게 설명해 볼 수 있는가?
    * 주로 Address translation은 실행 시간에 수행됩니다. 실행시간(Execution time)에 수행되기 때문에 빠르게 이뤄져야해서 H/W의 도움을 받습니다. 
    * Contiguous Allocation: 연속적으로 저장이 되어있을 때 프로세스에 메모리 시작위치가 저장되어 있는 것(`Relocation register`)을 이용합니다. 그리고 limit을 구하여 시작주소에 limit을 더해 Physical Address를 구합니다. 만약 시작주소가 범위를 넘어간다면 잘못된 주소로 인식합니다.
        * 연속적으로 저장을 하게 될 경우 `Fragmentation`(단편화)가 발생합니다. 
            * External fragmentation: 연속적으로 저장할 시 남아있는 메모리 공간이 지금 필요한 메모리 공간 보다 크지만 남아있는 메모리 공간이 단편화 되어 있어 할당을 할 수 없는 상태를 말합니다.
            * Internal fragmentation: paging단위로 나누어져 있을 때 그 공간에 할당이 될 경우 딱 나누어 떨어지지 않는 메모리 공간은 사용할 수 없는 현상을 말합니다. 만약 paging단위가 4KB인데 필요공간이 2KB일 경우 나머지 2KB는 사용할 수 없게 됩니다.
    * Paging: Contiguous하게 저장을 하지 않아도 괜찮아 집니다. 주로 paging단위는 4KB로 두고 Physical memory 단위인 frame 또한 동일하게 두고 사용하게 됩니다. 중간에 `Page table`을 두어 Physical memory의 frame# + offset으로 시작 주소를 찾게 됩니다. Page table은 PCB에 존재하게 됩니다. 이 경우 Internal fragmentation의 위험이 있습니다. 이 경우 `TLB(Translation Lookup Buffer)`나 register에 page table을 두어 빠르게 주소 변환이 되도록 H/W의 도움을 받습니다. TLB는 모든 Page table의 내용이 올라가는 것이 아니라 Hit율이 높은 것을 올려 빠르게 처리하도록 하는 구조입니다. page table에 valid bit를 두어 protection을 하게 됩니다.
        * page table을 2-level, 3-level 계층적으로 두어 page table의 서치 타임을 증가 시킬수 있습니다. 또한 해싱을 시켜 관리할 수도 있습니다. 
    * Segmentation: 논리적으로 구분한 단위인 `Segment`를 기반으로 연속적으로 저장하게 됩니다. 이 경우 `Segment table`로 관리하게 되는데 연속적으로 저장이 되어있어 시작주소를 알면 바로 위치를 찾을 수 있습니다. 

## 9장(Virtual Memory Management)

1. Swapping의 과정을 설명해봐라.
    1. 먼저 OS가 PCB의 테이블을 보고 valid, invalid한지 메모리에 있는지를 판단합니다. 메모리에 없다면 `Page fault`입니다. 
    2. 그리고 free frame을 가지고 와서 
    3. swapping을 하고 valid bit를 valid로 바꿉니다. valid는 메모리에 있다는 것을 의미합니다. 
    4. 그리고! 프로세스를 수행합니다. 
2. 만약 free frame이 없다면 어떻게 되는가?
    * victim, 즉 교체되어야 할 프레임을 찾아야 합니다. 이 swapping이 될 때는 victim을 찾고 그 victim을 valid bit를 invalid로 바꾼 뒤 원하는 page를 올리고 새로운 page의 테이블을 갱신해야하는 상당한 오버헤드가 있습니다. 그래서 여기서 최소로 page fault가 발생하도록 해야하는 알고리즘을 사용해야 합니다.
3. 그럼 그 page falut를 최소화 하는 방법이 뭐가있는데?
    * (흠?) frame이 증가하면 page falut도 감소하지 않을까 라고 생각하는데 오히려 증가하는 경우가 있다. 이러한 모순을 `Balady's Anomaly`라고 한다.
    1. FIFO(First In First Out): 먼저 온 순서대로 일을 처리한다. 
    2. Optimal Algorithm: 가장 나중에 쓰일 것을 victim으로 삼는다. 하지만 미래에 그게 가장 안쓰일지 어떻게 알까? 모른다. 그래서 LRU를 쓴다.
    3. LRU(Least Recently Used): 가장 이전에 쓰인 것을 victim으로 삼는다. 이 경우 시간을 기록하는 Counter, Stack을 이용하는 기법 등으로 구현이 가능하다. 
4. 쓰레싱에 대해 설명해봐라
    * 사람들이 multiprogramming이 증가하면 CPU Utilization이 증가한다고 생각하는데 어느 지점까지는 그 말은 옳다. 하지만 계속해서 멀티프로그래밍이 증가할 경우 메모리에는 한계가 있고 Paging in, out이 지속적으로 많이 증가하게 되면 Context Switch 오버헤드가 엄청나진다. 위에서 설명한 것처럼 프로세스에서 감당할 수 없이 Paging in, out이 증가하여 프로세스의 CPU utilization이 감소하는 현상을 쓰레싱이라 한다. 
    * 이 경우 locality를 고려하여 `Working Set model`을 사용하여 thrashing이 발생하는지 판단한다.
5. (흠?) kernel에서 메모리 할당은 어떻게 하나?
    * Buddy System: 메모리를 2의 n승의 크기로 할당한다. 분할과 병합을 지속적으로 진행하여 할당한다.
    * Slab Allocator: 연속적인 메모리 공간을 미리 할당하여 정확하게 메모리에 맞춰서 일을 할당한다. 


## 10장(File System)
> File System에 대한 설명이 들어간다.

1. File System에서 등장하는 Hard link 와 Soft link에 대해 구분할 수 있는가?
    * 실제 파일이 존재 하는 곳을 가리키는게 Hard link, 실제 파일을 가리키는 곳을 가리키는 게 Soft link이다. 가리키는 파일을 삭제했을때 Soft link일 경우 Dangling pointer가 발생한다.

## 11장(Implemeting File System)

1. File이 open될 때 어떻게 시스템이 작동하는지 설명해봐라
    1. 먼저 `System wide open file table`을 찾아봐서 이미 열려있는지 본다. 
    2. 이미 열려있다면 `per process open file table`을 하나 더 만들고 System wide open file table에서 FCB 정보를 얻어 열게된다.
    3. 없다면 Directory structure를 찾아 inode 넘버를 찾고 그것을 system wide open file table에 올린뒤 `per process open file table`을 하나 더 만들고 파일을 올리게 된다. 
2. read or write 할 때는?
    1. 먼저 per-process open file table을 보고 system wide open file table을 찾아간다.
    2. 그리고 FCB를 통해 file 의 위치를 찾고 read, write
3. close할 때는?
    * per-process open file table을 지우고
    * system-wide open file table에 연결되어있는 것의 갯수를 보고 없다면 삭제

## 12장(Secondary Storage Structure)

1. (흠?) 디스크 스케줄링 기법들이 뭐가 있을까?
    * FCFS : 들어온 순서대로 수행
    * SSTF(Shortest Seek Time First) : 헤드 근처에 있는 순서대로
    * SCAN : 안쪽 부터 바깥쪽까지 한번 쭈욱
    * C-SCAN: 한쪽 디렉션으로만 쭈욱
    * LOOK : queue에 담겨있는 최고 끝 점부터 끝점까지만 쭈욱
    * C-LOOK: LOOK과 동일하지만 한쪽 방향으로만
2. RAID 구조에서 문제가 생길 경우 해결하는 방안에 뭐가있을까?
    * mirroring: 중복해서 저장을 한다. 용량이 두배로 들게 된다.
    * parity: parity block을 두어 복구. XOR연산을 통해 복구가 가능해진다. 추가적인 메모리가 필요하지만 미러링 기법에 비해 적은 용량이 필요하다. 
3. parity를 사용할 때 발생할 수 있는 문제는 뭐가 있을까?
    * 추가적인 메모리가 사용된다는 점
    * `small write problem`: 작은 양의 write가 계속 될 때 parity를 매번 다시 계산을 해줘야 하므로 오버해드가 커지게 된다.

## 마치며
더 중요하고 외워야 하는 많은 사항들이 있을 것같다. 또 시대가 지남에 따라 많이 변한 내용또한 있을 것 같다. 이러한 부분을 지적해주시면 좋을 것 같다.

<br/><br/>
